# -*- coding: utf-8 -*-
"""Grad_desc.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IZwq4VXfORrH1c_Z-Q5u220MVJsarzLW
"""

import numpy as np
import random
import tensorflow as tf
from tensorflow import keras
import pandas as pd

npmain = np.zeros(300)
for i in range(0,300,3):
  for j in range(0,100):
    npmain[i]=int(random.randint(20,55))
    npmain[i+1]=int(random.randint(0,1))
    npmain[i+2]=int(random.randint(0,1))

npnew = npmain.reshape(100,3)

df = pd.DataFrame(npnew, columns=['Age','Income','Insurance'])
df.head(20)

from sklearn.model_selection import train_test_split
x_tr,x_t,y_tr,y_t = train_test_split(df[['Age','Income']],df.Income, test_size = 0.2, random_state = 123)

len(x_tr)

#Using Tensorflow
model = keras.Sequential([keras.layers.Dense(1, input_shape=(2,) , activation = 'sigmoid', 
                    kernel_initializer = 'ones', bias_initializer = 'zeros')])

model.compile(optimizer = 'adam', 
              loss = 'binary_crossentropy',
              metrics = ['accuracy'])

model.fit(x_tr,y_tr, epochs = 1000)

y_pred = model.predict(x_t)
y_pred[0]

y_t[0]



coef, intercept = model.get_weights()
print(f'With tensorflow weight w1,w2 = {coef} and bias = {intercept} so equation is \n y = {coef[0]}*x + {coef[1]}x + {intercept}')

#Without Tensorflow
def sigmoid(x):
    from math import exp
    return 1/(1+exp(-x))

sigmoid(18)

def prediction_function(age,income):
    weighted_sum = coef[0]*age + coef[1]*income + intercept
    return sigmoid(weighted_sum)

prediction_function(47,1)

def log_loss(y_t,y_pred):
    epsilon = 1e-15
    yp_new = [max(i,epsilon) for i in y_pred]
    yp_new = [min(i,1-epsilon) for i in yp_new]
    yp_new = np.array([yp_new])
    return -np.mean(y_t*np.log(yp_new) + (1-y_t)*np.log(1-yp_new))

def sigmoid_numpy(x):
  return 1/(1+np.exp(-x))

sigmoid_numpy(np.array([2,4,16,25]))

def grad_desc(age, income, y_t, epochs):
    w1 = 1
    w2 = 1
    bias = 0
    rate = 0.5
    n = len(age)

    for i in range(epochs):
        weighted_sum = w1 * age + w2 * income + bias
        y_predicted = sigmoid_numpy(weighted_sum)
        loss = log_loss(y_t,y_predicted)

        w1_derivate = (1/n) * np.dot(np.transpose(age),(y_predicted - y_t))
        w2_derivate = (1/n) * np.dot(np.transpose(income),(y_predicted - y_t))
        
        bias_derivative = np.mean(y_predicted - y_t)

        w1 = w1 - rate * w1_derivate
        w2 = w2 - rate * w2_derivate
        bias = bias - rate * bias_derivative

        print(f'Epoch: {i+1}, w1 : {w1} , w2 : {w2}, bias : {bias} \n')

    return w1,w2,bias

grad_desc(x_tr['Age'], x_tr['Income'], y_tr, 1000)

